---
layout: post
title: Thoughts on Writings about AI
date: 2026-01-13
tags:
  - MachineLearning
  - AI
teaser: A (growing) list of things that have made me thing about the role of AI in my job/life/planet
---
Recent advances in ML[^1] have introduced a lot of new capabilities[^2].  The degree and kind of change are driving a lot of interesting technology-and-society articles.  I'm collecting the ones that catch my attention here...

| Summary                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            | Commentary                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [Keep the Robots out of the Gym](https://danielmiessler.com/blog/keep-the-robots-out-of-the-gym): A simple rule for personally judging when AI should/not be used.  At "Work" the goal is to *move* a heavy object, and its OK to use a machine to do it.  In the "Gym" the goal is to *lift* a heavy object, and using a machine would defeat the purpose.                                                                                                                                                                                                                                                                                                        | This framing clarifies a lot of times that AI is/not appropriate: Is the goal for *me* to do or for it *to be done*?  Implicit in the discussion is that the AI does the thing well-enough to call it done...                                                                                                                                                                                                                                                                                                                                                                                                                       |
| [Why Aren't Smart People Happier](https://www.experimental-history.com/p/why-arent-smart-people-happier): There is a section in the middle that notes that AI takes all problems and reduces them to well-defined problems...wether appropriate or not.  The annecdote that made me laugh: "If you booted up a super-smart AI in ancient Greece, fed it all human knowledge, and asked it how to land on the moon, it would respond 'You can’t land on the moon. The moon is a god floating in the sky.' How would you get it to realize the moon is actually a big rock? That’s a great, poorly defined problem, and I don’t expect AI to solve it anytime soon." | "Well defined problems" are those are repeatable, involve stable relationships and answers are unambiguous.  All other problems are "poorly defined".<br><br>The implication is that people will always be important for "poorly defined" problems.  I think also in the knowledge-blindspot space.<br><br>I was also caught by the commentary that if we define all human/animal/plant as fitting under some category of "intelligence", then we loose the power of the category. It is hard to treat in/out judgements as not high/low value, but that doesn't mean the in/out judgement is not useful...just be careful with it! |
| [Vibe Engineering](https://simonwillison.net/2025/Oct/7/vibe-engineering/): The ability to *iterate* on code is what makes coding agents distinct.  Practice is converging toward running multiple agents at once on a codebase.  Agents work best when other software engineering practices are followed [^3]: Automated testing, advance planning, documentation, version control, effective automation, code-review culture, "weird management" in the agile manifest sense (I think), non-automated QA practices, preview/integration testing. <br><br>**Observation**: "AI tools amplify existing expertise".                                                 | Reminds me the concept that technology is a "force multiplier".  <br><br>I think the AI-thing is amplifying the impact of good and bad habits.  This will make some bad habits more painful, and possibly make them less common!                                                                                                                                                                                                                                                                                                                                                                                                    |
| [The next two years of Software Engineering](https://addyosmani.com/blog/next-two-years/): Professional strategies need to shift, but its not clear what the end-game looks like yet.  This post goes through how a Junior and Senior dev might strategically act now for many possible futures.  <br><br>**Observation:** Coding was never the sole task. Lean into those other tasks.<br><br>Closely related is [Choose Learning over Autopilot](https://anniecherkaev.com/choosing-learning-over-autopilot), but this later piece is more tactically focused.                                                                                                   | The most thorough analysis that I've seen of what people making software could keep focus on that will be important in a variety of futures.<br><br>There are concrete actions a software worker could take and those are spelled out here.  Though they mostly boil down to "Juniors, learn the fundamentals; Seniors, learn the new technology' they are actually more concrete to address specific potential/plausible futures.                                                                                                                                                                                                  |

Philosophy that has resonated:
- [Why Nietzsche Matters in the Age of Artificial Intelligence](https://cacm.acm.org/blogcacm/why-nietzsche-matters-in-the-age-of-artificial-intelligence/)
- [Don't turn of your brain](https://computingeducationthings.substack.com/p/22-dont-turn-your-brain-off)
- [Software Development in the Time of Strange New Angels](https://davegriffith.substack.com/p/software-development-in-the-time) 

Things that look specifically at agentic workflows:t
- [Tools on Claude](https://www.anthropic.com/engineering/advanced-tool-use)
- [Bitter lesson LLM extensions](https://www.sawyerhood.com/blog/llm-extension)


[^1]: It's often billed as advances in AI, but the subset of AI known as ML is the part that has improved. [The wikipedia article on AI](https://en.wikipedia.org/wiki/Artificial_intelligence) paints AI with a very broad brush...taken at face value its hard to think of a computational field that is not AI.  Compilers involve resource planning (which is AI), programming languages are at least a knowledge representation problem (which is AI) and have heavy reasoning components in their optimization (which is AI). Cryptography or Computational theory seem safe for now...That being said, I don't think  

[^2]: In 2019, new capabilities came from 'deep models', where you just do the neural-network thing but a thousand times in stead of three. In 2025 the advanced capabilities come from LLM, but I expect those to be passed sometime (though for marketing reasons the label may be with us for a lot longer than the language-based architectures).  

[^3]: Echoed in [AI Is Forcing us to Write Good Code](https://bits.logic.inc/p/ai-is-forcing-us-to-write-good-code), but the list of "best practices" is: 100% code coverage, Namespaces, Fast/Ephemeral/Concurrent dev environments, End-to-End Types.  Each list was drawn from the respective author's personal experience an not from a formal education, appeal-to-authority or survey of peers.  In practice, a best practice is probably at least partially context dependent, and similarly the ones that AI will emphasize or deprecate will also change project to project.  That being said, both lists lean heavily on *infrastructure* practices.